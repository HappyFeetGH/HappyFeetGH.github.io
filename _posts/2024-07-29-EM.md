---
title : EM (1)
date : 2024-07-29 11:15:00 +09:00
categories : [EM]
tag : [EM]
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Parameter estimation for mixutre modles

파라미터들은 안다고 가정하고 주어진 observed variables에 대한 hidden variables에 대한 사후확률을 계산하는 방법을 보는 것을 알아왔다.
이 장에선, 파라미터들을 학습하는 방법에 대해 토론한다.

10.4.2 장에서 complete data와 factored prior를 가질 때, 파라미터들에 대한 사후확률을 factorize하고 쉽게 계산을 만든다.

하지만, 만약 hidden variables 나 missing data를 가질때, 이는 더 이상 참이 아니다. 
왜냐하면 $$z_i$$가 관측되었을 때, d-separation에 의해 $$\theta_z \perp \theta_{x} | D$$를 확인할 수 있다. 
따라서 사후확률을 factorize할 수 있다.

LVM에서, $$z_i$$는 hidden이고, 파라미터들은 더 이상 독립적이지 않게 된다. 그래서 사후확률은 factorize되지 않고, 이를 계산하기 더 어렵게 만든다. 아래와 같이 이는 MAP와 ML estimates의 계산을 복잡하게 만든다.

## Unidentifiability

LVM에 대한 $$p(\theta|D)$$를 계산할 때의 주 문제:
 사후확률은 multiple modes(다수의 대푯값)을 갖는다.


이유: GMM을 고려할 때, $$z_i$$가 모두 관측되었다면, 파라미터들에 대한 unimodal posterior를 갖는다:


$$ p(\theta|D) = Dir(\pi |D)\prod_{k=1}^{K} NIW(\mu_{k}, \sum_{k}|D)$$

+ 결론: globally optimal MAP estimate를 쉽게 찾을 수 있다.


하지만 $$z_i$$들이 hidden일때, $$z_i$$로 패워진 가능한 방법들의 각각에 대해서 서로다른 unimodla likelihood를 얻는다.

따라서 $$z_i$$들에 대해서 marginalize out할때, $$p(\theta |D)$$를 위한 multi-modal posterior를 얻을 수 있다.

이러한 대푯값들은 군집들의 다른 labelings에 대응한다.

![image](https://github-production-user-asset-6210df.s3.amazonaws.com/141888688/353304106-dcfd1f67-6b64-43d9-b30f-f4c0eeda0dc0.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240730%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240730T034906Z&X-Amz-Expires=300&X-Amz-Signature=01f7ec8e94c8d43cfb77cb31ce93517ba5cdc4101e6b455e4de251cd4c36dc08&X-Amz-SignedHeaders=host&actor_id=141888688&key_id=0&repo_id=758327526)