---
title : EM (1)
date : 2024-07-29 11:15:00 +09:00
categories : [EM]
tag : [EM]
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# Parameter estimation for mixutre modles

파라미터들은 안다고 가정하고 주어진 observed variables에 대한 hidden variables에 대한 사후확률을 계산하는 방법을 보는 것을 알아왔다.
이 장에선, 파라미터들을 학습하는 방법에 대해 토론한다.

10.4.2 장에서 complete data와 factored prior를 가질 때, 파라미터들에 대한 사후확률을 factorize하고 쉽게 계산을 만든다.

하지만, 만약 hidden variables 나 missing data를 가질때, 이는 더 이상 참이 아니다. 
왜냐하면 $$z_i$$가 관측되었을 때, d-separation에 의해 $$\theta_z \perp \theta_{x} | D$$를 확인할 수 있다. 
따라서 사후확률을 factorize할 수 있다.

LVM에서, $$z_i$$는 hidden이고, 파라미터들은 더 이상 독립적이지 않게 된다. 그래서 사후확률은 factorize되지 않고, 이를 계산하기 더 어렵게 만든다. 아래와 같이 이는 MAP와 ML estimates의 계산을 복잡하게 만든다.

## Unidentifiability

LVM에 대한 $$p(\theta|D)$$를 계산할 때의 주 문제:
 사후확률은 multiple modes(다수의 대푯값)을 갖는다.


이유: GMM을 고려할 때, $$z_i$$가 모두 관측되었다면, 파라미터들에 대한 unimodal posterior를 갖는다:


$$ p(\theta|D) = Dir(\pi |D)\prod_{k=1}^{K} NIW(\mu_{k}, \sum_{k}|D)$$

+ 결론: globally optimal MAP estimate를 쉽게 찾을 수 있다.


하지만 $$z_i$$들이 hidden일때, $$z_i$$로 패워진 가능한 방법들의 각각에 대해서 서로다른 unimodla likelihood를 얻는다.