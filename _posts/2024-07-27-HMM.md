---
title : HMM (1)
date : 2024-07-27 07:15:00 +09:00
categories : [MachineLearning, HMM]
tag : [hmm]
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

# HMM 알아보기 (1)

파라미터들 $ \theta = (\pie, A, B) $ 를 어떻게 측정할 것인가에 대해 의논한다
+ $\pie(i) = p(z_1 = i)$는 initial state distribution 
+ $A(i,j) = p(z_t =j | z_{t-1} = i)$는 transition matrix 
+ $B$는 class-conditional densities $p(x_t|z_t=j)$의 파라미터들이다

+ 첫째로 $z_{1:T}가 training set엣관측되었을 때 경우를 고려한다. 그리고나서 $z_{1:T}가 hidden인경우의 harder case를 확인한다.


### Training with fully observed data
만약 hidden state sequences를 관측한다면 $A$나 $\pie$를 위한 MLEs를 정확하게 계산할 수 있다. 만약 conjugate prior를 사용한다면, 더 쉽게 사후확률을 계산할 수 있다.

+ observation model의 형태에 의존하는 $B$를 어떻게 평가하는지:
	+ 상황은 generative classifier를 fitting하는 것과 비슷하다
	+ 예시) 각 state가 그것과 관련된 parameters $B_{jl} = p(X_t = l| z_t = j)$를 갖고 $l \in \{ 1, \dots, L \}$ 인 multinoulli distribution을 가질 때,observed symbol을 다음과 같이 표현한다
		+ MLE: $ \hat{B_{jl}} = \frac{N^X_jl}{N_{j}}, N^X_{jl} \triangleq \sum{i=1}{N}\sum{t=1}{T_i} \parallel (z_{i,t} = j, x_{i,t} = l ) $
	+ 위 결과가 말하는 것: state $j$ 에있는 횟수를 추가하고 symbol $l$ 을 확인한다. 그 후 state $j$ 에 있는 횟수만큼 나누면 된다.

유사하게, 만약 state가 그것과 관계된 Gaussian distribution을 갖는다면,다음과 같은 MLEs를 갖는다:
$$ \hat{\mu_k} = \frac{\bar{x}_k}{N_k}, \hat{\sum{}{k}} = \frac{(\bar{x}\bar{x})^T_k - N_k \hat{\mu_k} \hat{\mu^T_k}}{N_k}$$

$$\bar{x}_k \triangleq \sum{i=1}{N} \sum{t=1}{T_i} \parallel (z_{i,t} = k)x_{i,t}$$
$$ (\bar{x}\bar{x})^T_k \triangleq \sum{i=1}{N} \sum{t=1}{T_i} \parallel (z_{i,t} = k) x_{i,t} x^T_{i,t} $$

다른 종류의 분포에도 유사한 결과가 나온다. MAP 측정값 또는 파라미터에 대한 full 사후확률으ㄹ 구하기 위해 모든 이러한 결과들의 확장이 쉽게 가능하다

### EM for HMMs(the Baum-Welch algorithm)

	